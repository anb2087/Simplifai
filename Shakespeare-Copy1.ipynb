{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,cv2,re\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import pickle\n",
    "from fastai.text import*\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START OF MEDICAL STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"_id\" : { \"$oid\" : \"55ff25239ad446c56ba8b321\" }, \"hl7_json_history\" : [], \"finalized_date\" : null,'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fh = open('/home/hoc2003/trove-data/trove-studies.json')\n",
    "studies_string = fh.read()\n",
    "fh.close()\n",
    "studies_string[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_array = []\n",
    "temp = None\n",
    "counter=0\n",
    "for study in studies_string.split('\\n'):\n",
    "    try:\n",
    "        temp = json.loads(study)\n",
    "        t=temp['finalized_report']\n",
    "        if t != None:\n",
    "            report_array.append(t)\n",
    "        #report_array.append(temp['finalized_report'])\n",
    "    except:\n",
    "        counter=counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THis is for all\n",
    "all_lat, all_other, all_c=get_impressions(report_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1146939"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(report_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|Ordered: 09/20/2015 05:05 PM       PATIENT NAME: MONAGHAN, LETICIA G       |Location: G05S5414-A               MRN: 02575061                           |                                   Age: 64 yrs  Sex: F                     |Adm M.D.: CHUNG, MIRIAM MD         DOB: 07/14/1951                         | |Exam Date:  Accession #:   Exam Code:     Order MD:                     |09/20/2015  *4995593       NCTHDBNWO      CHOE, BIANCA JUDY DO          |Clinical Statement: Sepsis, due to unspecified organism [A41.9].|Seizure.| |Technique: Multiple contiguous axial images were obtained from the skull|base to the vertex without the use of intravenous contrast.| |Comparison: February 11, 2007. | |Findings:| |Smooth, uniform hypodensity seen in along the falx and bilateral|cerebellar tentorium, new since the prior study of 2007. There is also|high density within the circle of Willis vessels. Gray-white|differentiation is preserved. There is no mass, mass effect or|herniation. Low-attenuation within the supratentorial white matter is|most compatible with chronic microvascular ischemia but nonspecific. The|ventricles and sulci are proportionate an compatible with mild|generalized volume loss. There is no hydrocephalus.| |Extensive calcifications of the bilateral cavernous internal carotid|arteries are present, as well as extracranial vessels bilaterally. There|is no expansile or destructive osseous lesion. The visualized paranasal|sinuses and mastoid air cells are clear.| |Impression:| |Since the prior study of February 11, 2007, there is new smooth high|density along the falx and bilateral cerebellar tentorium. This probably|represents retained intravenous contrast from the CT performed|yesterday, and high density within the circle of Willis vessels with|support this. Subdural hemorrhage could have a similar appearance but is|felt to be less likely. A repeat head CT under patient receives dialysis|is suggested for confirmation.| | |These findings were discussed with Dr BIANCA JUDY CHOE, DO on 9/20/2015|6:24 PM with read back verification.| |  Prepared By: Lantos, Joshua MD                                              |  Study interpreted and report approved by: Lantos, Joshua MD                 |  Electronically signed Diagnostic Report Imaging Report                      |  09/20/2015 05:50 PM - 09/20/2015 06:28 PM                                   |  Exam Complete - Signed-Off                                                  '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_array[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_array = []\n",
    "front_array = []\n",
    "counter = 0\n",
    "for x in report_array:\n",
    "    if re.search(r'DXCHPALAT', x) != None:\n",
    "        lat_array.append(x)\n",
    "    if re.search(r'DXMCH1V', x) != None:\n",
    "        front_array.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impressions(arr):\n",
    "    lst=[]\n",
    "    other=[]\n",
    "    counter=0\n",
    "    for x in arr:\n",
    "        if re.search(r'IMPRESSION\\:(.*?)Prepared By',x)!= None:\n",
    "            y=re.search(r'IMPRESSION\\:(.*?)Prepared By',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'Impression\\:(.*?)Prepared By',x) !=None:\n",
    "            y=re.search(r'Impression\\:(.*?)Prepared By',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'Impression(.*?)Prepared By',x) != None:\n",
    "            y=re.search(r'Impression(.*?)Prepared By',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'IMPRESSION(.*?)Prepared By',x) != None:\n",
    "            y=re.search(r'IMPRESSION(.*?)Prepared By',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        else:\n",
    "            counter=counter+1\n",
    "            other.append(x)\n",
    "    return lst,other,counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_findings(arr):\n",
    "    lst=[]\n",
    "    other=[]\n",
    "    counter=0\n",
    "    for x in arr:\n",
    "        if re.search(r'Findings\\:(.*?)Impression',x)!= None:\n",
    "            y=re.search(r'Findings\\:(.*?)Impression',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'Findings \\:(.*?)Impression',x)!= None:\n",
    "            y=re.search(r'Findings \\:(.*?)Impression',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'FINDINGS\\:(.*?)IMPRESSION',x) != None:\n",
    "            y=re.search(r'FINDINGS\\:(.*?)IMPRESSION',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'Findings\\:(.*?)IMPRESSION',x) != None:\n",
    "            y=re.search(r'Findings\\:(.*?)IMPRESSION',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'FINDINGS/IMPRESSION\\:(.*?)Prepared By',x) != None:\n",
    "            y=re.search(r'FINDINGS/IMPRESSION\\:(.*?)Prepared By',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'FINDINGS / IMPRESSION\\:(.*?)Prepared By',x) != None:\n",
    "            y=re.search(r'FINDINGS / IMPRESSION\\:(.*?)Prepared By',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'Findings/impression\\:(.*?)Prepared By',x) != None:\n",
    "            y=re.search(r'Findings/impression\\:(.*?)Prepared By',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'Findings/Impression\\:(.*?)Prepared By',x) != None:\n",
    "            y=re.search(r'Findings/Impression\\:(.*?)Prepared By',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        elif re.search(r'Findings and Impression\\:(.*?)Prepared By',x) != None:\n",
    "            y=re.search(r'Findings and Impression\\:(.*?)Prepared By',x).group(1)\n",
    "            z=y.replace('|',' ').strip()\n",
    "            lst.append(re.sub(' +',' ',z))\n",
    "        else:\n",
    "            counter=counter+1\n",
    "            other.append(x)\n",
    "    return lst,other,counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_im, lat_o, lic = get_impressions(lat_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_findings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c5ca5b384794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlat_fin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_fo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_findings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_findings' is not defined"
     ]
    }
   ],
   "source": [
    "lat_fin, lat_fo, lfc = get_findings(lat_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_fin, front_fo, ffc = get_findings(front_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin=lat_fin + front_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_lower(s):\n",
    "   if len(s) == 0:\n",
    "      return s\n",
    "   else:\n",
    "      return s[0].lower() + s[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_upper(s):\n",
    "   if len(s) == 0:\n",
    "      return s\n",
    "   else:\n",
    "      return s[0].upper() + s[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.reader(open('rad-dict.csv', 'r'))\n",
    "d = {}\n",
    "for row in reader:\n",
    "   k, v = row\n",
    "   d[k.replace('\"','')]=v.replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        if text.find(i)>0:\n",
    "            text = text.replace(i, first_lower(j))\n",
    "        elif text.find(first_upper(i))>0:\n",
    "            b=first_upper(i)\n",
    "            text = text.replace(b,first_lower(j))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_report(arr):\n",
    "    mod=[]\n",
    "    for re in arr:\n",
    "        mod.append(replace_all(re, d))\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for alll again\n",
    "new_all=mod_report(all_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped=zip(all_lat,new_all)\n",
    "qs=list(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lat_im = mod_report(lat_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped=zip(lat_im,new_lat_im)\n",
    "qs=list(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fin=mod_report(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped=zip(fin,new_fin)\n",
    "qs=list(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_qs, n_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_tok = Tokenizer.proc_all((o_qs),'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_tok = Tokenizer.proc_all((n_qs),'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['tubes',\n",
       "  'and',\n",
       "  'lines',\n",
       "  ':',\n",
       "  'none',\n",
       "  '.',\n",
       "  'lungs',\n",
       "  '/',\n",
       "  'pleura',\n",
       "  ':',\n",
       "  'lung',\n",
       "  'volumes',\n",
       "  'are',\n",
       "  'slightly',\n",
       "  'low',\n",
       "  ',',\n",
       "  'which',\n",
       "  'results',\n",
       "  'in',\n",
       "  'mild',\n",
       "  'crowding',\n",
       "  'of',\n",
       "  'the',\n",
       "  'perihilar',\n",
       "  'vasculature',\n",
       "  '.',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'new',\n",
       "  'focal',\n",
       "  'airspace',\n",
       "  'consolidation',\n",
       "  '.',\n",
       "  'no',\n",
       "  'pleural',\n",
       "  'effusion',\n",
       "  'or',\n",
       "  'pneumothorax',\n",
       "  'is',\n",
       "  'identified',\n",
       "  '.',\n",
       "  'a',\n",
       "  'calcified',\n",
       "  'nodule',\n",
       "  'in',\n",
       "  'the',\n",
       "  'periphery',\n",
       "  'of',\n",
       "  'the',\n",
       "  'right',\n",
       "  'lung',\n",
       "  'is',\n",
       "  'unchanged',\n",
       "  '.',\n",
       "  'mediastinum',\n",
       "  ':',\n",
       "  'the',\n",
       "  'cardiomediastinal',\n",
       "  'silhouette',\n",
       "  'is',\n",
       "  'at',\n",
       "  'the',\n",
       "  'upper',\n",
       "  'limits',\n",
       "  'of',\n",
       "  'normal',\n",
       "  'for',\n",
       "  'size',\n",
       "  '.',\n",
       "  'other',\n",
       "  ':',\n",
       "  'no',\n",
       "  'displaced',\n",
       "  'rib',\n",
       "  'fracture',\n",
       "  'is',\n",
       "  'identified',\n",
       "  ',',\n",
       "  'however',\n",
       "  'in',\n",
       "  'the',\n",
       "  'setting',\n",
       "  'of',\n",
       "  'chest',\n",
       "  'pain',\n",
       "  'if',\n",
       "  'there',\n",
       "  'is',\n",
       "  'high',\n",
       "  'clinical',\n",
       "  'suspicion',\n",
       "  'for',\n",
       "  'rib',\n",
       "  'injury',\n",
       "  ',',\n",
       "  'a',\n",
       "  'dedicated',\n",
       "  'rib',\n",
       "  'series',\n",
       "  'is',\n",
       "  'recommended',\n",
       "  '.'],\n",
       " ['tubes',\n",
       "  'and',\n",
       "  'lines',\n",
       "  ':',\n",
       "  'none',\n",
       "  '.',\n",
       "  'lungs',\n",
       "  '/',\n",
       "  'pleura',\n",
       "  ':',\n",
       "  'lung',\n",
       "  'volumes',\n",
       "  'are',\n",
       "  'slightly',\n",
       "  'low',\n",
       "  ',',\n",
       "  'which',\n",
       "  'results',\n",
       "  'in',\n",
       "  'mild',\n",
       "  'crowding',\n",
       "  'of',\n",
       "  'the',\n",
       "  'perihilar',\n",
       "  'vessels',\n",
       "  '.',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'new',\n",
       "  'focal',\n",
       "  'airspace',\n",
       "  'consolidation',\n",
       "  '.',\n",
       "  'no',\n",
       "  'fluid',\n",
       "  'around',\n",
       "  'the',\n",
       "  'lungs',\n",
       "  'or',\n",
       "  'partial',\n",
       "  'collanterior',\n",
       "  'to',\n",
       "  'posteriorse',\n",
       "  'of',\n",
       "  'lung',\n",
       "  'is',\n",
       "  'identified',\n",
       "  '.',\n",
       "  'a',\n",
       "  'calcified',\n",
       "  'nodule',\n",
       "  'in',\n",
       "  'the',\n",
       "  'periphery',\n",
       "  'of',\n",
       "  'the',\n",
       "  'right',\n",
       "  'lung',\n",
       "  'is',\n",
       "  'unchanged',\n",
       "  '.',\n",
       "  'mediastinum',\n",
       "  ':',\n",
       "  'the',\n",
       "  'heart',\n",
       "  'shadow',\n",
       "  'is',\n",
       "  'at',\n",
       "  'the',\n",
       "  'upper',\n",
       "  'limits',\n",
       "  'of',\n",
       "  'normal',\n",
       "  'for',\n",
       "  'size',\n",
       "  '.',\n",
       "  'other',\n",
       "  ':',\n",
       "  'no',\n",
       "  'displaced',\n",
       "  'rib',\n",
       "  'fracture',\n",
       "  'is',\n",
       "  'identified',\n",
       "  ',',\n",
       "  'however',\n",
       "  'in',\n",
       "  'the',\n",
       "  'sendotrachealting',\n",
       "  'of',\n",
       "  'chest',\n",
       "  'pain',\n",
       "  'if',\n",
       "  'there',\n",
       "  'is',\n",
       "  'high',\n",
       "  'clinical',\n",
       "  'suspicion',\n",
       "  'for',\n",
       "  'rib',\n",
       "  'injury',\n",
       "  ',',\n",
       "  'a',\n",
       "  'dedicated',\n",
       "  'rib',\n",
       "  'series',\n",
       "  'is',\n",
       "  'recommended',\n",
       "  '.'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ol_tok[4], ne_tok[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.0, 36.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(o) for o in ol_tok], 90), np.percentile([len(o) for o in ne_tok], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.array([len(o)<110 for o in ol_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_tok = np.array(ol_tok)[keep]\n",
    "ne_tok = np.array(ne_tok)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name1= \"1origional.pkl\"\n",
    "fileObject1=open(file_name1, 'wb')\n",
    "pickle.dump(ol_tok,fileObject1)\n",
    "file_name2= \"1modified.pkl\"\n",
    "fileObject2=open(file_name2, 'wb')\n",
    "pickle.dump(ne_tok,fileObject2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ol_tok, (Path('1origional').open('wb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ne_tok, (Path('1modified').open('wb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_tok = pickle.load((Path('1origional')).open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_tok = pickle.load((Path('1modified')).open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject1.close()\n",
    "fileObject1=open(file_name1, 'rb')\n",
    "ol_tok=pickle.load(fileObject1)\n",
    "fileObject2.close()\n",
    "fileObject2=open(file_name2, 'rb')\n",
    "ne_tok=pickle.load(fileObject2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH1=Path('fastai/courses/andrea/data/translation/tmp')\n",
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    temp = None\n",
    "    ids = []\n",
    "    for p in tok:\n",
    "        if p != None:\n",
    "            temp = []\n",
    "            for o in p:\n",
    "                temp.append(stoi[o])\n",
    "            temp += [2]\n",
    "            ids.append(temp)\n",
    "    ids = np.array(ids)\n",
    "    print(len(ids))\n",
    "    np.save(f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-00f8f32f07aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en1_ids.npy en1_itos.pkl en_ids.npy en_itos.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2129\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/alias.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, rest)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnargs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;31m#-----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2259\u001b[0m         \u001b[0;31m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m         \u001b[0;31m# Instead, we store the exit_code in user_ns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawnb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pexpect-U\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<pexpect factory incomplete>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         self.ptyproc = self._spawnpty(self.args, env=self.env,\n\u001b[0;32m--> 303\u001b[0;31m                                      cwd=self.cwd, **kwargs)\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptyproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_spawnpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;34m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mptyprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPtyProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/ptyprocess/ptyprocess.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_native_pty_fork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;31m# Use internal fork_pty, for Solaris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/pty.py\u001b[0m in \u001b[0;36mfork\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mmaster_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslave_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHILD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Establish a new session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "rm en4_ids.npy en4_itos.pkl en5_ids.npy en5_itos.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100573\n",
      "100573\n"
     ]
    }
   ],
   "source": [
    "ol_ids,ol_itos,ol_stoi = toks2ids(ol_tok,'en4')\n",
    "ne_ids,ne_itos,ne_stoi = toks2ids(ne_tok,'en5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_ids,ol_itos,ol_stoi = load_ids('en4')\n",
    "ne_ids,ne_itos,ne_stoi = load_ids('en5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['no',\n",
       "  'focal',\n",
       "  'pulmonary',\n",
       "  'consolidation',\n",
       "  '.',\n",
       "  'bilateral',\n",
       "  'pulmonary',\n",
       "  'nodules',\n",
       "  'again',\n",
       "  'noted',\n",
       "  '.',\n",
       "  '_eos_'],\n",
       " ['no',\n",
       "  'focal',\n",
       "  'lung',\n",
       "  'consolidation',\n",
       "  '.',\n",
       "  'bilateral',\n",
       "  'lung',\n",
       "  'nodules',\n",
       "  'again',\n",
       "  'noted',\n",
       "  '.',\n",
       "  '_eos_'],\n",
       " 6518,\n",
       " 6535)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ol_itos[o] for o in ol_ids[0]], [ne_itos[p] for p in ne_ids[0]], len(ol_itos), len(ne_itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs = ft.load_model(str('data/translate/wiki.en.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open('data/translate/wiki.en.pkl','wb'))\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = get_vecs('en', en_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = pickle.load(open('data/translate/wiki.en.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2519370"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_words = en_vecs.get_words(include_freq=True)\n",
    "ft_word_dict = {k:v for k,v in zip(*ft_words)}\n",
    "ft_words = sorted(ft_word_dict.keys(), key=lambda x: ft_word_dict[x])\n",
    "\n",
    "len(ft_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_en_vec = len(en_vecd[','])\n",
    "dim_en_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3874772e-05, 0.016063333)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vecs = np.stack(list(en_vecd.values()))\n",
    "en_vecs.mean(),en_vecs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 56)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nelen_90 = int(np.percentile([len(o) for o in ne_ids], 90))\n",
    "ollen_90 = int(np.percentile([len(o) for o in ol_ids], 97))\n",
    "nelen_90,ollen_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_ids_tr = np.array([o[:nelen_90] for o in ne_ids])\n",
    "ol_ids_tr = np.array([o[:ollen_90] for o in ol_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], self.y[idx])\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90488, 10085)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(ne_ids_tr))>0.1\n",
    "ne_trn,ol_trn = ne_ids_tr[trn_keep],ol_ids_tr[trn_keep]\n",
    "ne_val,ol_val = ne_ids_tr[~trn_keep],ol_ids_tr[~trn_keep]\n",
    "len(ne_trn),len(ne_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = Seq2SeqDataset(ol_trn,ne_trn)\n",
    "val_ds = Seq2SeqDataset(ol_val,ne_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(ne_trn, key=lambda x: len(ne_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(ne_val, key=lambda x: len(ne_val[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= Path ('fastai/courses/andrea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(56, 37), (9, 9), (8, 8), (10, 10), (16, 16)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w]*3)\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh,nl = 276,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqStepper(Stepper):\n",
    "    def step(self, xs, y, epoch):\n",
    "        self.m.pr_force = (10-epoch)*0.1 if epoch<10 else 0\n",
    "        xtra = []\n",
    "        output = self.m(*xs, y)\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "        self.opt.zero_grad()\n",
    "        loss = raw_loss = self.crit(output, y)\n",
    "        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
    "        loss.backward()\n",
    "        if self.clip:   # Gradient clipping\n",
    "            nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
    "        self.opt.step()\n",
    "        return raw_loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_All(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz_dec, bias=False)\n",
    "        self.drop_enc = nn.Dropout(0.25)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "        self.W1 = rand_p(nh*2, em_sz_dec)\n",
    "        self.l2 = nn.Linear(em_sz_dec, em_sz_dec)\n",
    "        self.l3 = nn.Linear(em_sz_dec+nh*2, em_sz_dec)\n",
    "        self.V = rand_p(em_sz_dec)\n",
    "\n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res,attns = [],[]\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            w2h = self.l2(h[-1])\n",
    "            u = F.tanh(w1e + w2h)\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
    "            emb = self.emb_dec(dec_inp)\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1))\n",
    "            \n",
    "            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "        return torch.stack(res)\n",
    "\n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl*2, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689 ['t_up', 'cardiomediastinal', '1', '2', 'bibasilar']\n",
      "1963 [':', 'collanterior', 'posteriorse', 't_up', '1']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN_All(en_vecd, ol_itos, dim_en_vec, en_vecd, ne_itos, dim_en_vec, nh, nelen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b815651fc4cd4a8b9f1f8a5414b137da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                 \n",
      "    0      0.821994   4.593583  \n",
      "    1      0.533991   3.58592                                  \n",
      "    2      0.301432   0.956787                                 \n",
      "    3      0.39523    0.613469                                 \n",
      "    4      0.287747   0.747216                                 \n",
      "    5      0.319285   0.426235                                 \n",
      "    6      0.42677    0.336947                                 \n",
      "    7      0.347047   0.201694                                 \n",
      "    8      0.2396     0.170382                                 \n",
      "    9      0.166429   0.126209                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.12621])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=10, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new nodular opacity overlying the left lung apex which may be within or external to the patient . repeat radiographs without overlying artifacts such as clothing , gown material , or telemetry pads recommended for further evaluation . _eos_\n",
      "new nodular opacity overlying the left lung anterior to posteriorex which may be within or external to the patient . repeat x - rays without overlying artifacts such as clothing , gown material , or telemendotrachealry pads\n",
      "new nodular opacity overlying the left lung anterior to posteriorex which may be within or external to the patient . repeat x - rays without overlying artifacts such as clothing , gown material , or pads pads\n",
      "\n",
      "1 . no radiographic evidence of acute cardiopulmonary disease . 2 . 1.1 cm nodular opacity projecting within the right upper lung zone may represent confluence of shadows as no correlate is identified on the lateral projection , however the possibility of a pulmonary lesion is raised . correlation with any prior imaging examination is recommended\n",
      "1 . no x - ray evidence of acute cardiolung disease . 2 . 1.1 cm nodular opacity projecting within the right upper lung zone may represent confluence of shadows as no correlate is identified on the\n",
      "1 . no x - ray evidence of acute cardiolung disease . 2 . marked cm nodular opacity projecting within the right upper lung zone may represent confluence of shadows as as correlate is identified on the\n",
      "\n",
      "lines / tubes : none . lungs / airways / pleura : unchanged blunting of the bilateral costophrenic angles , possibly tiny effusion or chronic changes . no pneumothorax . mediastinum / heart : the cardiomediastinal silhouette is unchanged . bones / soft tissue : no aggressive lesion . upper abdomen : unremarkable . _eos_\n",
      "lines / tubes : none . lungs / airways / pleura : unchanged blunting of the bilateral space bendotrachealween chest and lung angles , possibly tiny fluid around the lungs or chronic changes . no partial collanterior\n",
      "lines / tubes : none . lungs / airways / pleura : unchanged blunting of the bilateral space bendotrachealween chest chest angles , , likely fluid around the lungs or chronic changes . no partial collanterior to\n",
      "\n",
      "interval worsening in the appearance of the chest with findings of progressive multifocal pneumonia with increased right lower lobe and anterior lingular patchy opacities . small bilateral associated pleural effusions . follow - up to resolution is advised . _eos_\n",
      "interval worsening in the anterior to posteriorpearance of the chest with findings of progressive multifocal lung infection with increased right lower lobe and anterior lingular patchy opacities . small bilateral associated fluid around the lungss . follow\n",
      "interval worsening in the anterior to posteriorpearance of the chest with findings of minimally multifocal lung infection with increased right lower lobe and anterior lingular patchy opacities . small bilateral associated fluid around the lungss . follow\n",
      "\n",
      "mild reticulonodular opacities , most significant in the right upper lobe , may reflect chronic interstitial changes or an infectious / inflammatory process in the appropriate clinical setting . mild enlargement of the cardiac silhouette and tortuous thoracic aorta . _eos_\n",
      "mild rendotrachealiculonodular opacities , most significant in the right upper lobe , may reflect chronic lung changes or an infectious / inflammatory process in the anterior to posteriorpropriate clinical sendotrachealting . mild enlargement of the cardiac shadow\n",
      "mild rendotrachealiculonodular opacities , most compatible in the right upper lobe , may reflect chronic lung changes or an infectious / inflammatory process in the anterior to posteriorpropriate clinical sendotrachealting . mild enlargement of the cardiac shadow\n",
      "\n",
      "lines / tubes : none . lungs / airways / pleura : no consolidation or pleural effusion . no pneumothorax . mediastinum / heart : the cardiomediastinal silhouette is unchanged . bones / soft tissue : no aggressive lesion . upper abdomen : unremarkable . _eos_\n",
      "lines / tubes : none . lungs / airways / pleura : no consolidation or fluid around the lungs . no partial collanterior to posteriorse of lung . mediastinum / heart : the heart shadow is unchanged\n",
      "lines / tubes : none . lungs / airways / pleura : no consolidation or fluid around the lungs . no partial collanterior to posteriorse of lung . mediastinum / heart : the heart shadow is unchanged\n",
      "\n",
      "lines / tubes : none . lungs / airways / pleura : small bilateral pleural effusions are best seen on the lateral view , not visible on the frontal view . there is no focal consolidation . no pneumothorax . mediastinum / heart : the thoracic aorta is uncoiled and mildly tortuous . the cardiac silhouette\n",
      "lines / tubes : none . lungs / airways / pleura : small bilateral fluid around the lungss are best seen on the lateral view , not visible on the frontal view . there is no focal\n",
      "lines / tubes : none . lungs / airways / pleura : small bilateral fluid around the lungss are best seen on the lateral view , not external on the frontal view . there is no focal\n",
      "\n",
      "lines / tubes : none . lungs / airways / pleura : no consolidation or pleural effusion . no pneumothorax . mediastinum / heart : patient is status post median sternotomy and t_up cabg . cardiac silhouette is within normal limits on the frontal view . there is mild uncoiling of the thoracic aorta . bones\n",
      "lines / tubes : none . lungs / airways / pleura : no consolidation or fluid around the lungs . no partial collanterior to posteriorse of lung . mediastinum / heart : patient is status post median\n",
      "lines / tubes : none . lungs / airways / pleura : no consolidation or fluid around the lungs . no partial collanterior to posteriorse of lung . mediastinum / heart : patient is status post median\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(120,128):\n",
    "    print(' '.join([ol_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([ne_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([ne_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(' '.join([ol_itos[o] for o in x[:,i] if o != 1]), open('source.txt', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(' '.join([ne_itos[o] for o in preds[:,i] if o!=1]), open('ref.txt', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52812"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"source1.txt\", \"w\")\n",
    "f.write(' '.join(ol_itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54877"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('ref1.txt','w')\n",
    "f.write(' '.join(ne_itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "s=open('source2.txt', 'w')\n",
    "r=open('ref2.txt', 'w')\n",
    "for i in range(1,128):\n",
    "    s.write(' '.join([ol_itos[o] for o in x[:,i] if o != 1]))\n",
    "    s.write(\"\\n\")\n",
    "    r.write(' '.join([ne_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    r.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
